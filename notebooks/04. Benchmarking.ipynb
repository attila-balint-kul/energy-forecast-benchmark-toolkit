{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from typing import Any\n",
    "from datetime import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import enfobench as efb\n",
    "from enfobench.datasets import ElectricityDemandDataset, PVGenerationDataset, GasDemandDataset\n",
    "from enfobench.datasets.utils import create_perfect_forecasts_from_covariates\n",
    "from enfobench.evaluation.metrics import (\n",
    "    mean_bias_error,\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "from enfobench.evaluation.utils import periods_in_duration, create_forecast_index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the datasets",
   "id": "d424dfc30df3217b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edd = ElectricityDemandDataset(\"../data/electricity-demand\")\n",
    "edd"
   ],
   "id": "93828eb99d3a041e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pvd = PVGenerationDataset(\"../data/pv-generation\")\n",
    "pvd"
   ],
   "id": "e19ee160cdd0371f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdd = GasDemandDataset(\"../data/gas-demand\")\n",
    "gdd"
   ],
   "id": "1b032bdad5c8cbce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Number of buildings in the {edd.__class__.__name__}: {len(edd.metadata_subset.list_unique_ids())}\")\n",
    "print(f\"Number of buildings in the {pvd.__class__.__name__}: {len(pvd.metadata_subset.list_unique_ids())}\")\n",
    "print(f\"Number of buildings in the {gdd.__class__.__name__}: {len(gdd.metadata_subset.list_unique_ids())}\")"
   ],
   "id": "4c06fc86b5bd680f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edd.metadata_subset.read().freq.unique()\n",
    "print(f\"Available frequencies in the {edd.__class__.__name__}: {edd.metadata_subset.read().freq.unique().tolist()}\")\n",
    "print(f\"Available frequencies in the {pvd.__class__.__name__}: {pvd.metadata_subset.read().freq.unique().tolist()}\")\n",
    "print(f\"Available frequencies in the {gdd.__class__.__name__}: {gdd.metadata_subset.read().freq.unique().tolist()}\")"
   ],
   "id": "89fa8501c79bd935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Models\n",
    "### Naive Seasonal Model"
   ],
   "id": "90dec278a1efd518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statsforecast.models import SeasonalNaive, HistoricAverage, SeasonalWindowAverage\n",
    "\n",
    "\n",
    "class SeasonalNaiveModel:\n",
    "    def __init__(self, seasonality: str = \"1D\"):\n",
    "        self.seasonality = seasonality.upper()\n",
    "\n",
    "    def forecast(\n",
    "            self,\n",
    "            horizon: int,\n",
    "            history: pd.DataFrame,\n",
    "            past_covariates: pd.DataFrame | None = None,\n",
    "            future_covariates: pd.DataFrame | None = None,\n",
    "            metadata: dict | None = None,\n",
    "            level: list[int] | None = None,\n",
    "            **kwargs,\n",
    "    ) -> pd.DataFrame:\n",
    "        # Fill missing values\n",
    "        y = history.y.fillna(history.y.mean())\n",
    "\n",
    "        # Create model\n",
    "        periods = periods_in_duration(y.index, duration=self.seasonality)\n",
    "        model = SeasonalNaive(season_length=periods)\n",
    "\n",
    "        # Make forecast\n",
    "        pred = model.forecast(y=y.values, h=horizon, level=level, **kwargs)\n",
    "\n",
    "        # Create index for forecast\n",
    "        index = create_forecast_index(history=history, horizon=horizon)\n",
    "\n",
    "        # Postprocess forecast\n",
    "        forecast = pd.DataFrame(index=index, data=pred).rename(columns={\"mean\": \"yhat\"}).fillna(y.mean())\n",
    "        return forecast\n",
    "\n",
    "\n",
    "daily_naive_model = SeasonalNaiveModel(seasonality='1d')\n",
    "weekly_naive_model = SeasonalNaiveModel(seasonality='7d')"
   ],
   "id": "51fbaa6ac47563c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Benchmarking",
   "id": "d0f303073dc999aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_model_on_building(\n",
    "    *,\n",
    "    dataset: efb.Dataset,\n",
    "    unique_id: str,\n",
    "    model: Any,\n",
    "    cv_folds: int,\n",
    "    cv_step: pd.Timedelta,\n",
    "    cv_horizon: pd.Timedelta,\n",
    "    cv_time: str = time(hour=0, minute=0), \n",
    "    initial_training_period: pd.Timedelta = pd.Timedelta(\"28 days\"),\n",
    "    metrics: dict[str, Any] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Evaluate model on a single building.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset object.\n",
    "        unique_id: Unique identifier of the building.\n",
    "        model: Model object.\n",
    "        cv_folds: Number of cross-validation folds.\n",
    "        cv_step: Step size for cross-validation.\n",
    "        cv_horizon: Forecast horizon for cross-validation.\n",
    "        cv_time: Time when the forecasts are made, defaults to midnight.\n",
    "        initial_training_period: Initial available training period at the first prediction.\n",
    "        metrics: Metrics to evaluate. Defaults to [MBE, MAE, RMSE].\n",
    "        \n",
    "    Returns:\n",
    "        Cross-validation results and metrics.\n",
    "    \"\"\"\n",
    "    # Load data for building\n",
    "    target, past_covariates, metadata = dataset.get_data_by_unique_id(unique_id)\n",
    "\n",
    "    # Create perfect forecasts from past covariates\n",
    "    future_covariates = create_perfect_forecasts_from_covariates(\n",
    "        past_covariates[\n",
    "            ['temperature_2m', 'relative_humidity_2m', 'wind_speed_10m', 'wind_direction_10m', 'cloud_cover']],\n",
    "        start=pd.Timestamp(\"2013-01-01T00:00:00\"),\n",
    "        horizon=pd.Timedelta(\"4 days\"),\n",
    "        step=pd.Timedelta(\"24 hour\"),\n",
    "    )\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = efb.Dataset(\n",
    "        target=target,\n",
    "        past_covariates=past_covariates,\n",
    "        future_covariates=future_covariates,\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "    # Cross-validate model\n",
    "    start_date = (dataset.target_available_since + initial_training_period + pd.Timedelta(\"1 day\")).replace(hour=cv_time.hour, minute=cv_time.minute)\n",
    "    end_date = start_date + cv_folds * cv_step + cv_horizon\n",
    "    print(f\"Training data is available from '{dataset.target_available_since}' until '{dataset.target_available_until}'\")\n",
    "    print(f\"Evaluating model from '{start_date}' to '{end_date}', with {cv_folds} folds, '{cv_step}' step, and '{cv_horizon}' horizon.\")\n",
    "    crossval_df = efb.evaluation.cross_validate(\n",
    "        model,\n",
    "        dataset,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        horizon=cv_horizon,\n",
    "        step=cv_step,\n",
    "    )\n",
    "\n",
    "    # Evaluate metrics\n",
    "    default_metrics = {\n",
    "        \"MBE\": mean_bias_error,\n",
    "        \"MAE\": mean_absolute_error,\n",
    "        \"RMSE\": root_mean_squared_error,\n",
    "    }\n",
    "    metrics = efb.evaluation.evaluate_metrics(\n",
    "        crossval_df,\n",
    "        metrics=metrics or default_metrics,\n",
    "        groupby=\"cutoff_date\",\n",
    "    )\n",
    "    return crossval_df, metrics"
   ],
   "id": "daed1b254b14434a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example evaluation\n",
    "evaluate_model_on_building(\n",
    "    dataset=edd, \n",
    "    unique_id=edd.metadata_subset.list_unique_ids()[0], \n",
    "    model=daily_naive_model,\n",
    "    cv_folds=10,\n",
    "    cv_step=pd.Timedelta(\"1 day\"),\n",
    "    cv_horizon=pd.Timedelta(\"1 day\"),\n",
    ")"
   ],
   "id": "cb643c18d2122c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_buildings(dataset, n_buildings: int, seed: int = 42) -> list[str]:\n",
    "    \"\"\"Sample buildings from dataset.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    metadata = dataset.metadata_subset.read().dropna()\n",
    "    return np.random.choice(metadata.unique_id.values, n_buildings)\n",
    "\n",
    "def benchmark_model(\n",
    "    dataset, \n",
    "    unique_ids: list[str],\n",
    "    model: Any,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Benchmark model on multiple buildings.\"\"\"    \n",
    "    results = []\n",
    "    for unique_id in unique_ids:\n",
    "        print(f\"Benchmarking model on building '{unique_id}'\")\n",
    "        _, metrics = evaluate_model_on_building(dataset=dataset, unique_id=unique_id, model=model, **kwargs)\n",
    "        metrics['unique_id'] = unique_id\n",
    "        results.append(metrics)\n",
    "        \n",
    "    return pd.concat(results).set_index(['unique_id', 'cutoff_date']).drop(columns='weight')"
   ],
   "id": "327d86eb0a27b879",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run benchmarking with baseline model",
   "id": "c5fdacc0efe74238"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ed_leaderboard = pd.DataFrame()",
   "id": "fc08a2dc7a840ab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = edd\n",
    "buildings = sample_buildings(dataset, n_buildings=5)\n",
    "cv_folds = 10\n",
    "cv_step = pd.Timedelta(\"1 day\")\n",
    "cv_horizon = pd.Timedelta(\"1 day\")\n",
    "baseline_model = daily_naive_model"
   ],
   "id": "d4fb45b6ec427575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "baseline_results_df = benchmark_model(dataset, buildings, baseline_model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)",
   "id": "3cd5e1b53a28a197",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SeasonalNaiveModel(seasonality='1D')\n",
    "model_results_df = benchmark_model(dataset, buildings, model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)\n",
    "model_results_df['rMAE'] = (model_results_df / baseline_results_df).loc[:, \"MAE\"]\n",
    "ed_leaderboard['DailyNaiveSeasonal'] = model_results_df.mean()"
   ],
   "id": "d5bd62abc9d74384",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SeasonalNaiveModel(seasonality='7D')\n",
    "model_results_df = benchmark_model(dataset, buildings, model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)\n",
    "model_results_df['rMAE'] = (model_results_df / baseline_results_df).loc[:, \"MAE\"]\n",
    "ed_leaderboard['WeeklyNaiveSeasonal'] = model_results_df.mean()"
   ],
   "id": "b24aa0b7833cf4cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Placeholder model to benchmark, change this to the model you want to benchmark\n",
    "class HistoricAverageModel:\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: pd.DataFrame,\n",
    "        past_covariates: pd.DataFrame | None = None,\n",
    "        future_covariates: pd.DataFrame | None = None,\n",
    "        metadata: dict | None = None,\n",
    "        level: list[int] | None = None,\n",
    "        **kwargs,\n",
    "    ) -> pd.DataFrame:\n",
    "        # Fill missing values\n",
    "        y = history.y.fillna(history.y.mean())\n",
    "\n",
    "        # Create model\n",
    "        model = HistoricAverage()\n",
    "\n",
    "        # Make forecast\n",
    "        pred = model.forecast(y=y.values, h=horizon, level=level, **kwargs)\n",
    "\n",
    "        # Create index for forecast\n",
    "        index = create_forecast_index(history=history, horizon=horizon)\n",
    "\n",
    "        # Postprocess forecast\n",
    "        forecast = pd.DataFrame(index=index, data=pred).rename(columns={\"mean\": \"yhat\"}).fillna(y.mean())\n",
    "        return forecast\n",
    "    \n",
    "\n",
    "model = HistoricAverageModel()\n",
    "model_results_df = benchmark_model(dataset, buildings, model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)\n",
    "model_results_df['rMAE'] = (model_results_df / baseline_results_df).loc[:, \"MAE\"]\n",
    "ed_leaderboard['HistoricAverage'] = model_results_df.mean()"
   ],
   "id": "c5592bb9a3be7f91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Placeholder model to benchmark, change this to the model you want to benchmark\n",
    "class SeasonalWindowAverageModel:\n",
    "    \n",
    "    def __init__(self, seasonality: str, window_size: int):\n",
    "        self.seasonality = seasonality.upper()\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: pd.DataFrame,\n",
    "        past_covariates: pd.DataFrame | None = None,\n",
    "        future_covariates: pd.DataFrame | None = None,\n",
    "        metadata: dict | None = None,\n",
    "        level: list[int] | None = None,\n",
    "        **kwargs,\n",
    "    ) -> pd.DataFrame:\n",
    "        # Fill missing values\n",
    "        y = history.y.fillna(history.y.mean())\n",
    "\n",
    "        # Create model\n",
    "        periods = periods_in_duration(y.index, duration=self.seasonality)\n",
    "        model = SeasonalWindowAverage(season_length=periods, window_size=self.window_size)\n",
    "\n",
    "        # Make forecast\n",
    "        pred = model.forecast(y=y.values, h=horizon, **kwargs)\n",
    "\n",
    "        # Create index for forecast\n",
    "        index = create_forecast_index(history=history, horizon=horizon)\n",
    "\n",
    "        # Postprocess forecast\n",
    "        forecast = pd.DataFrame(\n",
    "            index=index,\n",
    "            data={\n",
    "                \"yhat\": pred[\"mean\"],\n",
    "            },\n",
    "        ).fillna(y.mean())\n",
    "        return forecast\n",
    "    \n",
    "\n",
    "model = SeasonalWindowAverageModel(\"1D\", 28)\n",
    "model_results_df = benchmark_model(dataset, buildings, model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)\n",
    "model_results_df['rMAE'] = (model_results_df / baseline_results_df).loc[:, \"MAE\"]\n",
    "ed_leaderboard['SeasonalWindowAverageS1DW28'] = model_results_df.mean()"
   ],
   "id": "86312b6c8b3875aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SeasonalWindowAverageModel(\"7D\", 4)\n",
    "model_results_df = benchmark_model(dataset, buildings, model, cv_folds=cv_folds, cv_step=cv_step, cv_horizon=cv_horizon)\n",
    "model_results_df['rMAE'] = (model_results_df / baseline_results_df).loc[:, \"MAE\"]\n",
    "ed_leaderboard['SeasonalWindowAverageS7DW4'] = model_results_df.mean()"
   ],
   "id": "1c6a8dd0645623ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ed_leaderboard.T.round(2).sort_values(\"rMAE\")",
   "id": "edb26327f91c508b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = ed_leaderboard.T.sort_values(\"rMAE\", ascending=False).rMAE.plot(kind='barh', figsize=(10, 5), title='Electricity Demand Leaderboard', xlabel='rMAE')\n",
    "plt.show()"
   ],
   "id": "ca53db6a92e74387",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1e0389d29f96f53e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
